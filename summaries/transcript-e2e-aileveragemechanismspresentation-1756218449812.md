# meeting transcript - gemini 2.5 flash end-to-end

**audio file:** audio-temp/twitter-video-test.wav
**processing time:** 94424ms
**cost:** $0.0853

---

create an enhanced transcript showing minute-by-minute emotional journey:

### formatting requirements:
- all lowercase: names, annotations, everything
- @person references when identifiable (@speaker1, @speaker2, @you)
- _topic emphasis_: _key themes_, _important concepts_
- emotional color coding: ðŸŸ¡ excitement, ðŸ”´ tension, ðŸ”µ focus, ðŸŸ¢ resolution, ðŸŸ  concern
- conversation blocks grouped by theme, not just chronological

### structure:
[timestamp range] what's happening + emotional context ðŸŸ¡/ðŸ”´/ðŸ”µ/ðŸŸ¢/ðŸŸ 
brief description of conversational or emotional shift

[timestamp] @person: "actual quote"
           (insight about this moment)

[topic shift] when conversation moves to different context


[00:00-00:02] @speaker1 initiates the meeting with a warm and casual introduction, setting a relaxed tone. ðŸ”µ

[00:00] @speaker1: "so, do you want to maybe give a really quick intro of yourself before we get started?"
(standard meeting opener, shows politeness and structure)

[00:02-00:01:30] @speaker2 provides a brief introduction, mentioning his work on ai, particularly at openai, and expressing excitement about _reasoning_ and _agents_. ðŸŸ¡

[00:02] @speaker2: "yeah sure. um so uh i'm and good to be here today. so um i have been working on this ai stuff for a few years uh and um i have at openai i've been mainly um focusing on o1 preview o1 and most recently deep research and now i'm more on the this agent side of things and so um yeah very excited about reasoning and uh agents and just those things um so"
(positive and enthusiastic, sets a positive tone for the technical discussion to follow)

[00:01:30-00:05:00]  @speaker2 uses a _chatgpt-generated image_ of a budding flower as a metaphor to illustrate the challenge of perceiving slow, incremental change, especially regarding the rapid development of _ai_. ðŸ”µðŸŸ 

[00:01:30] @speaker2: "okay great. um right let me get started. so uh i will talk about some ai stuff today obviously but before that let's actually um start looking at um let's see. right uh this chatgpt generated uh image of a flower a budding flower. if you stare at this um for like a minute or 10 minutes you don't really see any change. does that mean there is no change underlying this process. there is and if you wait long enough then you'll see some big changes to a full blown uh rose. and so what i'm trying to get at with this toy image is that we're really not good at um perceiving the changes that occur in you know like minute or like even the days or years but we're pretty good at the minute and hour scale changes. so i think there's probably a evolutionary explanation for this uh where if you can uh perceive the changes in um in the environment uh and the changes in minutes probably very helpful for survival and if you for like changes in over a year not so much. um so i think that probably uh is some some built in um uh the deficiency uh uh that we probably need to correct."
(Thought-provoking analogy; introduces a key theme of underestimation of slow-moving changes in the face of rapid technological advancement.)


[00:05:00-00:15:00] @speaker2 introduces the _concept of leverage_ as a central theme,  using examples from classical mechanics (lever), finance (capital), and software (code).  He explains that _AI_ acts as a new leverage mechanism. ðŸ”µ

[00:05:00] @speaker2: "so um why am i talking about this? i think um actually ai is a probably the the fastest moving technology of all time. even then it doesn't move in like minutes or hours it still moves over a few years timeframe or even decades. so um i think given this um deficiency i just talked about we might be underestimating the change especially the magnitude of the change uh this ai is bringing about. and so um i think at this point i don't have to convince that ai is important even a few years ago i start um my talk like that but now i think that's given but i do want to emphasize that maybe what everyone's thinking about how big of this change is uh is very different uh and if anything think we might be underestimating it and especially for um this ai which i'm gonna argue as a leverage mechanisms for uh individuals and humanity as a whole that aspect uh might be somewhat underestimated. i'll get into the details of what what i mean by that but let's build uh intuition slowly at a time starting with this key word leverage. so it's a very important concept and used in a somewhat um casual way informally and sometimes overloaded and and um depends on this context. uh especially in the silicon valley area this term is used a lot. i think this is such an important word that uh it's worth spending some time and building intuition around this. so uh for me the first encounter of this concept was probably this classical mechanics where uh we have this uh lever. so in this case let's think about this um try to uh put a some pressure force down on the left hand side on the screen and then as an output of that the the the we're kind of um lifting up that 1 kilogram uh mass on the right. so the lever if we enlarge this uh lever um and then we can actually um you know lift up heavier objects. so what this means is that the input downward force is the same but by increasing this leverage the output was increased by 3x. and so um this actually is a very general concept and i would like to um call out uh maybe this is my working definition of leverage it's a mechanism through which a small change or no change in input results in larger change or very large change in output. um and this is a very general thing and it's not just about the classical mechanics context that we just saw i think it can be applied to many other places. um and so this actually is a um you know very important concept and i you know we many people want to increase the output i want to um contribute more i want to generate more um then the first thing the most natural thing that comes to uh our mind uh is probably how do i work harder how can i increase my input um i want to like sleep less and um um you know things like that but i think that's there's a certain limit to it. instead the more important question is how do i increase the output without actually increasing the input or how can i disconnect the relationship between the input and the output or linear relationship between them and that is getting at uh to the core of this leverage mechanism and so what you're looking for there is um what leverage mechanism do i have and can i have and that's uh if you want to increase the output that's the question that we have to think about."


[00:15:00-00:20:00] @speaker2 discusses three types of leverage identified by naval ravakant: _human labor_, _capital_, and _code/media_.  He provides examples of each, emphasizing the exponential potential of code and media. ðŸ”µ

[00:15:00] @speaker2: "and as a general concept many many um different ways of thinking about this leverage my personal favorite is by uh naval ravakant and from this um book actually i have it um you know in the and here i strongly recommend it so this is um uh not by his book but it's just a collection of uh many of his thoughts like uh tweets and so on. according to naval there are three uh types of uh leverage and human labor capital and code and media. so let's think about uh these things um uh individually. so first type is the human labor and this is the oldest type of uh leverage and and as such probably the most familiar one. and so as an example um let's think about a scenario where i want to build a pyramid without the leverage i will be building alone and that's probably quite difficult and with leverage i can hire uh thousands of human workers and so my input uh is probably the same or uh even less i don't don't have to work as much but the output is much higher because there are thousands of people working on this. so this is um kind of a uh the leverage type with the permission because i need to ask the permissions of these uh people and uh we still have this uh human labor as one of the main leverage mechanisms in the society. second type is the capital. so uh let's think about this um a scenario where i want to invest in a real estate uh that's worth a million dollar i only have 200k so i do borrow 800k from the bank and let's say i get lucky and this thing gets um doubled in valuation to 2 million um i it just doubled but my uh return is 800% or 500% but it just went up by like a lot more because i just borrowed more from it. um and so this is kind of the uh second type and i think it's more of a common common thing for uh 20th century and and so on. so third type is more recent uh thing especially more common in the the area which is the code and so more of a software type and so if i write a code for an app i build it and then there's one user who gets the value n um let's suppose that number is positive and while i'm sleeping one more user downloads it and installs it and gets another value n. so i'll put just double without me having to do any additional work. so it's possible because it's a software which is uh you know copied and pasted which is a very interesting nature of this and a lot of the recent value has been created uh leveraging that so and media is similar in that um let's say i uh give a lecture to 200 people um those people got some value again assuming that's uh positive i posted on youtube any additional view of the same lecture i don't have to do any work but somehow the value goes up and the limit is actually um uh pretty much endless. so that's the the new type of leverage too. in historically large wealth creation um utilize these forms of leverage and so um like the 20th centuries uh wealth a lot of them financial industries um leverage a lot of this capital leverage and then um recently especially in this um area tech companies have leveraged the fact that if you write a code the output can be multiplied pretty much indefinitely."


[00:20:00-00:25:00] @speaker2 explains how the upside of leverage mechanisms can be competed away, illustrating this with examples from software and youtube. He argues that _AI_ is changing what's scarce, shifting the focus to creativity and curiosity.  ðŸŸ 

[00:20:00] @speaker2: "and then um so those are the wealth creation mechanisms and if you look at the history of wealth um big wealth generated and you can probably identify such a leverage. so but then the upside of the leverage mechanism is also um competed away and so what i mean by that is if something is good then many people realize it and that's gonna be um uh competition. so if you start a company that is only leveraging this um the fact that it's a software doesn't leverage other technologies then it's probably much harder to uh succeed now compared to say 20 years ago or maybe um i'm less familiar with this but youtuber you want to become a youtuber now probably more difficult than um 10 years uh ago just based on the competition. so i what i'm trying to get at is um when this leverage mechanism is uh just became possible because of some technology much larger values and returns are possible then uh and then it's gonna be competed away. so i think it's a really important to think about what are the new leverage mechanisms that are becoming available."


[00:25:00-00:30:00]  @speaker2 discusses how _AI_ is affecting learning and acting as a leverage mechanism, particularly in scientific research. He notes that while _AI_ makes learning easier, the scarce factor shifts to _motivation_ and _curiosity_. He also introduces the concept of _AI agents_ as a new leverage mechanism and explains their significance. ðŸ”µðŸŸ¡

[00:25:00] @speaker2: "and so um obviously i'm gonna argue that ai is the um relatively new one that is coming into the picture and it's slowly expanding its scope and reach. um so to from an individual levels to um you know groups of people and to the point where it can uh benefit uh entire humanity. so let's maybe start looking at this uh at an individual level. um i personally use ai or chatgpt for me is um it in a education context. so i um that's probably the biggest one for me and i think i spent a lot of time especially uh weekends uh just learning about new concepts and um asking now i think talk about this ai uh even hours and just learning about new things and so here just again if you think about leverage uh when i think about ai as in leverage uh this learning what what is an input and output the input is my time and effort to understand some concept that i don't understand and the output is the conceptual understanding happening uh in my brain and maybe also some knowledge but that's uh that's a important thing. so with the ai this given input results in um you know larger output. so let's say if i'm trying to um learn some specific things about a distributed system um then before this kind of a generative ai i would have to you know google this and then probably a wikipedia page which is typically not beginner friendly. so i'll be uh reading it then like don't understand and probably don't feel good and then i'll try to find a introductory course maybe and textbook but then i want only one concept out of this but i kind of have to build around the context like at least terminologies and that's very time consuming. now because the ai can uh contextualize everything i know and generate dynamically just the right amount of materials at the right difficulty i can uh much learn much easier. so i think that's the the the big uh lesson from the learning. so um what i'm saying is the barrier to learn in new area is like collapsing essentially. um this is good and you probably heard about this a lot but is this good just everywhere? i i think there's some uh we have to be careful and have a comprehensive look and then um when everything is um easier to learn people are learning everything then there is an opportunity cost of not learning is getting higher. um so as an extreme example if you don't use ai you just don't think about it at all and you just do your thing you're not lazy just doing your own thing and everyone else is just learning new things and uh getting better and um so on then you're kind of behind uh in the society. that's the opportunity cost of just you don't contribute to it but just because uh it's uh the the relatively um decided what the valuable skill is that's uh what's happening. so um yeah i think the in in this the society the valuable skill is um determined based on um the supply and demand and what is scarce um as opposed to an objective value it provides. so um i think one extreme example is a human vision um and it's uh from objective perspective this is a extremely complicated and advanced um feature and if you study the computer vision probably know that oh human vision is incredible like you sometimes recognize uh your friends or in a setting where probably is very difficult um and you got you sometimes get surprised. but this incredible um capability is so abundant um that it's uh having that doesn't help you excelling in the modern society. um and so i think um uh similarly just uh like scarcity is a very important um necessary condition for any uh highly valuable skill. so um and i often think about what are uh some great skills or opportunities to to have and often the good good um rule of thumb is uh whatever evolution did not teach equip us then um that's kind of the good starting point uh because if it did then everyone has it built into dna and that's probably not that uh scarce. so um that's kind of the yeah uh my this some implications of learning getting easier which is not probably not that uh obvious and so this acquisition of the new knowledge gets cheap the scarce factor is the this motivation to explore and curiosity is kind of the characteristics that probably will be more important so well i mean it has been always important but i think it's getting more and more um because the learning um cost is going down but not zero. so you still have to overcome this um barrier when learning a new concept is not something um that i would say everyone finds pleasing because you feel challenged and this cognitive um challenge is not um comfortable. and so to overcome that uh curiosity can be like i i know there's a pain but i need to get this because i'm so uh curious about it that's a really uh strong force. if you're not curious i think there's a way to kind of um have a correction mechanism um which is okay i i i'm gonna go through this short term pain but there will be a long term um rewards some fulfilling um things happening so if you build enough of this reward some psychological can uh get over it but but anyway uh broad more broadly technology changes what is scarce um just makes um and just being aware of the such changes um even if you're not directly contributing to it uh is um i think uh very important. so that's one uh learning affecting learning uh is one way ai is acting as a leverage the other maybe more um uh intuitive one is this uh ai agent uh this is probably the most um interesting research area in 2025 and many more. um so uh here ai agent is um kind of combining the uh the two types of leverage mechanisms that we uh saw before. first one's the human labor because ai agent is doing the work for you so that's kind of the human labor part uh as if you hired them and then the second part is um at least the the the current um ai agents are um you know software uh only and so you can kind of copy and paste if you want um 10 outputs 10 agents working together you just do it if you want 12 then just copy uh two more and you don't have to ask for the permission this permission less uh form of uh composite leverage mechanism that i think is uh quite profound if you think about it. um so i think that's gonna be um um main um source of uh wealth generation uh going forward and this thing is very new i think it's just got started. um i if you have used uh deep research that's um to me the most uh well functioning uh ai agent as of now uh there will be more probably but uh that's at least the the kind of the first working agent for me uh and so that increases my uh output by a lot and maybe probably many others too. so individuals are quite uh supercharged and this means um you know small teams consist of uh individuals um generating really big values that's becoming more and more common. so in the you might heard about the startups with like 10 people 20 people generating like hundreds of millions of dollars of revenue uh that probably is un uh just imaginable like 10 years ago but now still uncommon but uh we're seeing this and i think behind the scene uh it's more of a ai acting as a leverage and individuals are just generating a lot more um outputs. and so previously if you want to increase the output then you again you want to think about the leverage mechanism and after raising funds and whatever for capital leverage is out of question then you have to really think about this human labor leverage and hire more people but then uh human collaboration especially at larger scale has quite a bit of overhead um there's communication um you know just uh it's a very difficult uh problem um and maybe some people don't get along with uh other people and so just adding one person to say 100 person uh group doesn't mean the output goes up by 1%. it can even be um negative or uh can be anything. so um now with supercharged individuals this um overhead uh is becoming less favorable and maybe we'll see more and more of uh smaller teams generating um uh quite a bit of uh value and more of a companies might be of this size and obviously there will be big companies but this might be a more common thing."


[00:30:00-00:31:00] @speaker1 makes a comment referencing a past class discussion on _AI singularity_, prompting @speaker2 to pause the recording before responding. ðŸ”´

[00:30:00] @speaker1: "and i think so far this has been like an individual level and uh some implications of the group as a result. um i think there slowly uh again this is like a the the the flower analogy from the beginning this is a change that is very big but uh it's so slow that i think it's kind of an under uh estimated by many people and it's acting at the humanity's level. so let's think about uh this uh so if we think about the the this all of humans here um what is the the task or goals um we might have uh i think this there's no right answer but to me one of the most important things is to continue to generate um value and to thrive and so what is the most um sustainable engines of growth and um value creation uh there are many prob but for me the most sustainable engine is um scientific advances um discovering new knowledge and suddenly uh the like you know what you think about as a thought about as a non resource just becomes resource because now you have a new knowledge to leverage that um oil for example is just sticky uh liquid now you know how to do this uh burning this and thermodynamic understanding you can uh that's such a valuable resource um many instances like that."

[00:31:00-00:32:30]  @speaker2 continues discussing _AI's role in accelerating scientific progress_, touching upon the increasing complexity of modern science and comparing Newtonian physics to quantum mechanics. ðŸ”µ

[00:31:00] @speaker2: "so um here um if we think about from historical perspective since the like 17th century or roughly that time scientific revolution uh the the wealth creation just um uh like really took off and uh like a hockey stick uh shape of uh economic metric um since then. um and back then it was there were probably a lot of low hanging fruits in terms of the scientific progress uh because if you're the first one to do science then probably there's a lot of easy things to do. uh i'm not saying everything was easy because there's other challenges given the context but still from an objective complexity perspective this is probably much easier than what is happening now. so advancing science in modern society is a lot more complicated. so maybe we can think about uh newtonian versus quantum mechanics or if you want to make a um you know advanced uh chip making advanced computer chips uh that is probably beyond any single uh human's uh capability way beyond that. so it's getting a lot more complicated and involves uh sometimes involves larger collaborations among people and more capital and so on and also in addition to this uh increasing complexity of the technologies studying technologies human intelligence is not growing uh it's i don't even know it's growing but it's kind of a stagnant compared to the rate at which the scientific complexity increases. so um these factors uh put together i think are kind of the uh bottlenecks in uh further advancing this um core mission of uh keep advancing scientific progress. so um we have done great job whenever just um bottleneck happens we find a way to get uh out of it and we build the tools to unblock ourselves from achieving the mission. this time i think we should do the same thing with the ai being this tool that will um be the most useful thing and maybe even better a superhuman in the research capabilities so that we can continue this uh scientific advances and i i think there are many purposes of ai but to me this is the most um important single most important purpose of it is to augment uh in continuing this uh grand mission of scientific advances."


[00:32:30-00:33:30] @speaker2 summarizes his points again, focusing on the _input and output_ of human scientific effort, and how _AI_ can act as a leverage mechanism to overcome existing limitations (communication, collaboration). ðŸ”µ

[00:32:30] @speaker2: "so uh now again just from the perspective of the leverage uh let's think about the input and the output. the input is the collective human effort um scientists here and there uh just working together uh or like implicitly together uh and then the output is the scientific um you know this progress uh of all and so um what how can ai act as a leverage here um think i'm gonna mention like two different things. first one is um you know when um actually uh let's think about this uh we highly uh encourage being a specialist especially in the scientific community so it uh there are small number of people who have a specialized knowledge and they're kind of segregated in different even uh you know locations and communities and and so on. so it's hard to um collaborate uh you might not even know what is available option for collaboration across different uh expertise areas and so to me this uh if you think about this human knowledge and mental mental picture i have is a very sharp um in you know high high dimensional space and that's like here and there and just um there's so much uh space between them and i think ai is acting as a um kind of an envelope around this uh spiky uh space and connecting all these um you know the specialist knowledge and if you're familiar with the um optimization this is like the convex hull that's an envelope around this um sharp uh you know corners here and there and i think this is the um the the one of the roles of ai so this when i was uh working on the deep research this um wasn't really obvious but as i worked more and more and get more value out of it this is kind of the mental picture i started building and so um here i'm trying to get at this um human experts um very specialized but um their you know cooperation has uh communication physical separations all all these um uh overhead and this um ai is kind of making that much much um more uh uh you know efficient."


[00:33:30-00:35:00] @speaker2 further expands on the idea of _AI_ connecting disparate areas of expertise, envisioning _AI_ as a tool for knowledge synthesis and acceleration of scientific progress.  He concludes by emphasizing the potential of _AI_ as a super-human research capability. ðŸŸ¡

[00:33:30] @speaker2: "and so um what i'm what i think is uh might be happening already is uh because of those um separations um and not unable to cooperate in an efficient manner we might have a huge overhang of uh existing knowledge synthesis. so even with um you know just combining the existing knowledge we might be able to get a lot of value and maybe we can call that new knowledge and so those are the uh i think uh completely uncharted territory just because of how experts have uh grown and the communication bottlenecks of um uh many many people and so these are i think the low hanging fruits uh of ai you know acting as a leverage to advancing the science mission and but i don't think that's the that's enough uh we should probably go beyond and maybe just uh going forward uh we can expect advanced reasoning maybe even better than uh human scientists and then ability to generate new ideas and knowledge uh i think this is still rare and maybe i'm hearing some you know vague um uh anecdotes that these are possible um like o3 helping some scientists generating new ideas brainstorming partner but i think it can go a lot more than that and so i would expect that this kind of uh abilities emerge in the future generations of the model if not al already in there and once that happens this will be um you know just non stopping um research engine that have works all the time and then they can work together uh across humans and agents and so on. this will be the main um leverage factor going forward how ai can help help this uh mission of the scientific progress so um that's all i have today and i've talked about many different concepts but uh i think ai is just important thing everyone knows that but um i would invite you to think about is this um how big of a change am i um thinking about and uh is there a possibility that i might be underestimating uh that magnitude especially um now that you think about from a new form of leverage um i would invite you to think about this um yeah that's it thanks."

[00:35:00-00:36:00] @speaker1 thanks @speaker2, and then makes an observation linking the presentationâ€™s conclusion to the previous class discussion regarding the _AI singularity_.  She offers to share visual materials from the class to make the discussion more interactive. ðŸ”µ


[00:35:00] @speaker1: "thanks so much. um uh so your final point actually uh reminded me of something we talked about a couple weeks ago in the class called uh do you guys remember what it was called? uh we talked about the singularity and uh uh how ai intelligence uh will reach a level where uh they surpass human intel well you know obviously we're already at that point. um do you think it relates to uh concepts such as that?"


[00:36:00-00:36:30] @speaker2 pauses the recording, presumably to ensure the conversation remains off the record before continuing.  ðŸ”´