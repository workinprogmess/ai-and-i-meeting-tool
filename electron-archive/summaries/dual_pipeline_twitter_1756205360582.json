{
  "timestamp": 1756205360582,
  "audioFile": "audio-temp/twitter-video-test.wav",
  "fileSizeMB": 55.95,
  "totalProcessingTime": 79381,
  "results": {
    "pipelineA": {
      "provider": "whisper + gemini",
      "error": "whisper.transcribeAudioFile is not a function",
      "status": "failed"
    },
    "pipelineB": {
      "provider": "gemini-end-to-end",
      "result": {
        "provider": "gemini-2.5-flash-end-to-end",
        "fullOutput": "## Transcript\n\n[00:00] Speaker1: So, do you want to maybe give a really quick intro of yourself before we get started?\n\n[00:05] Speaker2: Yeah, sure. Um, so uh I'm [speaker2's name] and good to be here today. So, um I have been working on this AI stuff for a few years uh and um I have at OpenAI, I've been mainly um focusing on 01 preview, 01 and most recently Deep Research and now I'm more on the this agent side of things and so um yeah, very excited about reasoning and uh agents and just those things um so Okay, great. Um Right, let me get started. So uh I will talk about some AI stuff today, obviously, but before that, let's actually um start looking at um let's see. Right. Um this ChatGPT generated uh image of a flower, a budding flower. If you stare at this um for like a minute or 10 minutes, you don't really see any change. Does that mean there is no change underlying this process? There is. And if you wait long enough, then you'll see some big changes to a full-blown uh rose. And so what I'm trying to get at with this uh toy image is that we're really not good at um perceiving the changes that occur in, you know, like minute or like even uh days or years, but we're pretty good at um minute and hour scale changes. So I think there's probably a evolutionary explanation for this uh where if you can uh perceive the changes in um in the environment uh in the changes in minutes, probably very helpful for survival. And if you for like changes in over a year, not so much. Um so I think that probably uh is some some built-in um uh deficiency uh that we probably need to correct. So um why am I talking about this? I think um actually AI is a probably the the fastest moving technology of all time. Even then it doesn't move in like minutes or hours. It still moves over a few years timeframe or even decades. So um I think given this um deficiency I just talked about, we might be underestimating the change, especially the magnitude of the change uh this AI is bringing about. And so um I think at this point I don't have to convince that AI is important. Even a few years ago I start um my talk like that, but now I think that's given. But I do want to emphasize that maybe what everyone's thinking about how big of this change is uh is very different uh and if anything think we might be underestimating it and especially for um this AI which I'm gonna argue as a leverage mechanisms for uh individuals and humanity as a whole, that aspect uh might be somewhat underestimated. I'll get into the details of what what I mean by that, but let's build uh intuition slowly at a time, starting with this uh key word leverage. So it's a very important concept and used in a somewhat um casual way, informally and sometimes overloaded in and um depends on this context. Uh especially in the Silicon Valley area, this term is used a lot. I think this is such an important word that uh it's worth spending some time and building intuition around this. So uh for me, the first encounter of this concept was probably this classical mechanics where uh we have this uh lever. So in this case let's think about this um try to uh put it some pressure force down on the left-hand side on the screen and then as an output of that the the the we're kind of um lifting up that 1 kg uh mass on the right. So the lever, if we enlarge this uh lever um and then we can actually um you know, lift up heavier objects. So what this means is that the input downward force is the same, but by increasing this leverage, the output was increased by 3x. And so um this actually is a very general concept and I would like to um call out uh maybe this is my working definition of leverage. It's a mechanism through which a small change or no change in input results in larger change or very large change in output. Um and this is a very general thing and it's not just about the classical mechanics context that we just saw. I think it can be applied to many other places. Um and so this actually is a um you know, very important concept and I you know, we many people want to increase the output. I want to um contribute more, I want to generate more. Um then the first thing, the most natural thing that comes to uh our mind uh is probably how do I work harder? How can I increase my input? Um I want to like sleep less and um um you know, things like that. But I think that's there's a certain limit to it. Instead, the more important question is how do I increase the output without actually increasing the input? Or how can I disconnect the relationship between the input and the output or linear relationship between them? And that is getting at uh to the core of this leverage mechanism. And so what you're looking for there is um what leverage mechanism do I have and can I have? And that's uh if you want to increase the output, that's the question that we have to think about. And as a general concept, many many um different ways of thinking about this leverage. My personal favorite is by uh Naval Ravikant and from this um book, actually I have it um you know, in the in here. I strongly recommend it. So this is um uh not by his book, but it's just a collection of uh many of his thoughts like uh tweets and so on. According to Naval, there are three uh types of uh leverage and human labor, capital and code and media. So let's think about uh these things um uh individually. So first type is the human labor and this is the oldest type of uh leverage and and as such probably the most familiar one. And so as an example, um let's think about a scenario where I want to build a pyramid. Without the leverage, I will be building alone and that's probably quite difficult. And with leverage, I can hire uh thousands of human workers. And so my input uh is probably the same or uh even less, I don't have to work as much, but the output is much higher because there are thousands of people working on this. So this is um kind of a uh the leverage type with the permission because I need to ask the permissions of these uh people. And uh we still have this uh human labor as one of the main leverage mechanisms in the society. Second type is the capital. So uh let's think about this um a scenario where I want to invest in a real estate uh that's worth a million dollar. I only have 200k. So I do borrow 800k from a bank. And let's say I get lucky and this thing gets um doubled in valuation to 2 million. Um I it just doubled, but my uh return is 400% or 500% but it just went up by like a lot more because I just borrowed more from it. Um and so this is kind of the uh second type and I think it's more of a common common thing for uh 20th century and and so on. So third type is more recent uh thing especially more common in the the area, which is the code. And so more of a software type. And so if I write a code for an app, I build it and then there's one user who gets the value N. Um let's suppose that number is positive. And while I'm sleeping, one more user downloads it and installs it and gets another value N. So I'll put just double without me having to do any additional work. So this is possible because it's a software which is uh you know, copied and pasted, which is a very interesting nature of this and a lot of the recent value has been created uh leveraging that. So in media is similar in that um let's say I uh give a lecture to 200 people. Um those people got some value, again assuming that's uh positive. I posted on YouTube. Any additional view of the same lecture, I don't have to do any work, but somehow the value goes up and the limit is actually um uh pretty much endless. So that's the the new type of leverage too. And historically large wealth creation um utilizes these forms of leverage. And so um like the 20th centuries uh wealth a lot of them financial industries um leveraged a lot of this capital leverage. And then um recently, especially in this um area tech companies have leveraged the fact that if you write a code, the output can be multiplied pretty much indefinitely. And then um so those are the wealth creation mechanisms and if you look at the history of wealth um big wealth generated and you can probably identify such a leverage. So but then the upside of the leverage mechanism is also um competed away. And so what I mean by that is if something is good, then many people realize it and that's gonna be um uh competition. So if you start a company that is only leveraging this um the fact that it's a software, doesn't leverage other technologies, then it's probably much harder to uh succeed now compared to say 20 years ago. Or maybe um I'm less familiar with this, but YouTuber, you want to become a YouTuber now, probably more difficult than uh 10 years uh ago just based on the competition. So what I'm trying to get at is um when this leverage mechanism is uh just became possible because of some technology, much larger values and returns are possible then uh and then it's gonna be competed away. So I think it's a very important to think about what are the new leverage mechanisms that are becoming available. And so um obviously I'm gonna argue that AI is the um relatively new one that is coming into the picture and it's slowly expanding its the scope and reach. Um so to from an individual level to um you know, groups of people and to the point where it can uh benefit uh entire humanity. So let's maybe start looking at this uh at an individual level. Um I personally use AI or ChatGPT for me is um it in a education context. So I um that's probably the biggest one for me. And I think I spend a lot of time, especially uh weekends uh just learning about new concepts and um asking Now I think talk about this AI uh even hours and just learning about new things. And so here just again, if you think about leverage uh when I think about AI as a leverage, uh the learning what what is an input and output? The input is my time and effort to understand some concept that I don't understand. And the output is the conceptual understanding happening uh in my brain and maybe also some knowledge, but that's uh that's of an important thing. So with the AI this given input results in um you know, larger output. So let's say if I'm trying to um learn some specific things about a distributed system, um then before this kind of a generative AI, I would have to you know, Google this and then probably a Wikipedia page, which is typically not beginner friendly. So I'll be uh reading it, then I don't understand and probably don't feel good and then I'll try to find a uh introductory course maybe and textbook, but then I want only one concept out of this, but I kind of have to build around the context, at least terminologies and that's very time consuming. Now, because the AI can uh contextualize everything I know and generate dynamically just the right amount of materials at the right difficulty, I can uh much learn much easier. So I think that's the the the big uh lessons from the learning. So um what I'm saying is the barrier to learn a new area is like collapsing essentially. Um this is good and you probably heard about this a lot, but is this good just everywhere? I I think there's some uh we have to be careful and have a comprehensive look. And then um when everything is um easier to learn, people are learning everything, then there's an opportunity cost of not learning is getting higher. Um so as an extreme example, if you don't use AI, you just don't think about it at all and you just do your thing, you're not lazy, just doing your own thing and everyone else is just learning new things and uh getting better and um so on, then you're kind of behind uh in the society. That's the opportunity cost of just you don't contribute to it, but just because uh it's um the relatively um decided what the valuable skill is, that's uh what's happening. So um yeah, I think the in in this the society the valuable skill is um determined based on um the supply and demand and what is scarce um as opposed to an objective value it provides. So um I think one extreme example is a human vision. Um and it's a from objective perspective, this is a extremely complicated and advanced um feature. And if you study the computer vision, probably know that oh human vision is incredible. Like you sometimes recognize uh your friends or in a setting where it probably is very difficult um and you got you sometimes get surprised. But this incredible um capability is so abundant um that it's uh having that doesn't help you excelling in the modern society. Um and so I think um similarly just uh like scarcity is a very important um necessary condition for any uh highly valuable skill. So um and I often think about what are uh some great skills or opportunities to to have. And often a good good uh rule of thumb is uh whatever evolution did not teach equip us, then um that's kind of a good starting point uh because if it did, then everyone has it built into DNA and that's probably not that uh scarce. So um that's kind of the yeah, uh my this some implications of learning getting easier, which is not probably not that uh obvious. And so this acquisition of the new knowledge gets cheap, the scarcest factor is the the this motivation to to explore and curiosity is kind of the characteristics that probably will be more important. So, well I mean it has been always important, but I think it's getting more and more um because the learning um cost is going down but not zero. So you still have to overcome this um barrier. When learning a new concept is not something um that I would say everyone finds pleasing because you feel challenged and this cognitive um challenge is not um comfortable. And so to overcome that, uh curiosity can be like I I know there's a pain, but I need to get this because I'm so uh curious about it. That's a really uh strong force. If you're not curious, I think there's a way to kind of um have a correction mechanism, um which is okay, I I I'm gonna go through this uh short-term pain, but there will be a long-term um rewards, some fulfilling um things happening. So if you build enough of this rewards on psychological thing, we can uh get over it. But but anyway, uh broad more broadly technology changes what is scarce um just makes um and just being aware of the such changes um even if you're not directly contributing to it, uh is um I think uh very important. So that one uh learning affecting learning uh is one way AI is acting as a leverage. The other maybe more um uh intuitive one is this uh AI agent. Uh this is probably the most um interesting research area in 2025 and many more. Um so uh here AI agent is um kind of combining the uh the two types of leverage mechanisms that we uh saw before. First one is the human labor because AI agent is doing the work for you. So that's kind of the human labor part, uh as if you hired them. And then the second part is um at least the the the current um AI agents are um you know, software uh only. And so you can kind of copy and paste. If you want um 10 outputs, 10 agents working together, you just do it. If you want 12, then just copy uh two more. And you don't have to ask for the permission, just permissionless uh form of uh composite leverage mechanism that I think is uh quite profound if you think about it. Um so I think that's gonna be um um main um source of uh wealth generation uh going forward. And this thing is very new. I think it's just got started. Um I if you have used a Deep Research, that's um to me the most uh well functioning uh AI agent as of now. Uh there will be more probably, but uh that's at least uh the kind of the first uh working agent for me. Uh and so that increases my uh output by a lot and maybe probably many others too. So individuals are quite uh supercharged. And this means um you know, small teams consist of uh individuals um generating really big values. That's becoming more and more common. So in the you might heard about uh startups with like 10 people, 20 people generating like hundreds of millions of dollars of revenue. Uh that probably is un uh just imaginable like 10 years ago. But now still uncommon, but uh we're seeing this and I think behind the scene uh it's more of a AI acting as a leverage and individuals are just generating a lot more um outputs. And so previously, if you want to increase the output, then you again, you want to think about the leverage mechanism and after raising funds and whatever for capital leverage is uh out of question, then you have to really think about this human labor leverage and hire more people. But then uh human collaboration, especially at larger scale has quite a bit of overhead. Um there's communication, um you know, just uh it's a very difficult uh problem um and maybe some people don't get along with uh other people. And so just adding one person to say 100 person uh group doesn't mean the output goes up by 1%. It can even be um negative or uh can be anything. So um now with supercharged individuals, this um overhead uh is becoming less favorable and maybe we'll see more and more of uh smaller teams generating um uh quite a bit of uh value and more of a companies might be of this size. And obviously there will be big companies, but uh this might be a more common thing. And I think so far this has been like a individual level and uh some implications of the group as a result. Um I think there slowly uh again this is like a the the the flower analogy from the beginning, this is a change that is very big, but uh it's so slow that I think it's kind of an under uh estimated by many people and it's acting at the humanity's level. So let's think about uh this uh So if we think about the the just all of humans here, um what is the the task or goals um we might have? Uh I think this there's no right answer, but to me one of the most important things is to continue to generate um value and to thrive. And so what is the most um sustainable engines of growth and um value creation? Uh there are many probably, but for me the most sustainable engine is um scientific advances. Um discovering new knowledge and suddenly uh the like you know, what you think about as a thought about as a non-resource just becomes resource because now you have a new knowledge to leverage that um oil for example is just sticky uh liquid. Now you know how to do this um burn this and thermodynamic uh understanding you can uh that's a such a valuable resource. Um many instances like that. So um here um if we think about from historical perspective, since the like 17th century or roughly that time, scientific revolution uh the the wealth creation just um uh like really took off and like a hockey stick uh shape of uh economic metric um since then. Um and back then it was there were probably a lot of low hanging fruits in terms of the scientific progress uh because if you're the first one to do science, then probably there's a lot of easy things to do. Uh I'm not saying everything was easy because there's other challenges given the context, but still from an objective complexity perspective, this is probably much easier than what is happening now. So advancing science in modern society is a lot more complicated. So maybe we can think about uh Newtonian versus quantum mechanics or if you want to make a um you know, advanced uh chip making, advanced computer chips, uh that is probably beyond any single uh human's uh capability way beyond that. So it's getting a lot more complicated and involves um sometimes involves larger collaborations among people and more capital and so on. And also in addition to this uh increasing complexity of the technologies, studying technologies, human intelligence is not growing. Uh it's I don't even know it's growing, but it's kind of a stagnant compared to the rate at which the scientific complexity increases. So um these factors uh put together, I think are kind of the uh bottlenecks in the further advancing this um core mission of uh keep advancing scientific progress. So um we have done great job whenever just um bottleneck happens, we find a way to get uh out of it and we build the tools to unblock ourselves from uh achieving the mission. This time I think we should do the same thing with the AI being this tool that will um be the most useful thing and maybe even better a superhuman in the research capabilities so that we can continue this uh scientific advances. And I I think there are many purposes of AI, but to me this is the most um important, single most important purpose of it is to augment uh in continuing this uh grand mission of scientific advances. So uh now again just from the perspective of the leverage, uh let's think about the input and the output. The input is the collective human efforts um scientists here and there, uh just working together or like implicitly together. Uh and then the output is the scientific um you know, this progress uh of all. And so um what how can AI act as a leverage here? Um I think I'm gonna mention like two different things. First one is um you know, when um actually uh let's think about this. Uh we highly uh encourage being a specialist, especially in the scientific community. So uh there are small number of people who have a specialized knowledge and they're kind of segregated in different even uh you know, locations and communities and and so on. So it's hard to um collaborate. Uh you might not even know what is available option for collaboration across different uh expertise areas. And so to me this uh if you think about this human knowledge, a mental mental picture I have is a very sharp um in you know, high high-dimensional space and that's like here and there and just um there's so much uh space between them. And I think AI is acting as a um kind of an envelope around this uh spiky uh space and connecting all these um you know, the specialist knowledge. And if you're familiar with the um optimization, this is like the convex hole, this envelope around this um sharp uh you know, corners here and there. And I think this is the um the the one of the roles of uh AI. So this when I was uh working on the Deep Research, this um wasn't really obvious, but as I worked more and more and get more value out of it, this is kind of the mental picture I started building. And so um here I'm trying to get at this um human experts um very specialized, but um their you know, cooperation has uh communication, physical separations all all these um uh overhead. And this um AI is kind of making that much much um more uh you know, efficient. And so um what I'm what I think is uh might be happening already is uh because of those um separations um and uh unable to cooperate in an efficient manner, we might have a huge overhang of uh existing knowledge synthesis. So even with um you know, just combining the existing knowledge, we might be able to get a lot of value and maybe we can call that new knowledge. And so those are the uh I think uh completely uncharted territory just because of how experts have uh grown and the communication bottlenecks of um uh many many people. And so these are I think the low hanging fruits uh of AI you know, acting as a leverage to advancing the science mission. And but I don't think that's that's enough. Uh we should probably go beyond. And maybe just uh going forward uh we can expect advanced reasoning, maybe even better than uh human scientists and then ability to generate new ideas and knowledge. Uh I think this is still rare and maybe I'm hearing some you know, vague um uh anecdotes that these are possible, um like 03 helping some scientists generate new ideas, brainstorming partner, but I think it can go a lot more than that. And so I would expect that this kind of uh abilities emerge in the future generations of the model if not already in there. And once that happens, this will be um you know, just nonstop being um research engine that have works all the time and then they can work together uh across humans and agents and so on. This will be the main um leverage factor going forward, how AI can help help this uh mission of the scientific progress. So um that's all I have today and I've talked about many different concepts, but uh I think AI is just important thing everyone knows that, but um I would invite you to think about is this um how big of a change am I um thinking about and uh is there a possibility that I might be underestimating uh that magnitude especially um now that you think about from a new form of leverage. Um I would invite you to think about this. Um yeah, that's it. Thanks.\n\n[29:50] Speaker1: Thanks so much. Um Uh so your final point actually uh reminded me of something we talked about a couple weeks ago in the class called uh do you guys remember what it was called? Uh we talked about the singularity and uh uh how AI intelligence uh will reach a level where uh they surpass human intel Well, you know, obviously we're already at that point. Um do you think it relates to uh concepts such as that?\n\n[30:00] Speaker2: *Thoughtful pause, then a brief technical interruption regarding screen sharing.* Um not not because I'm going to say something. Okay, yeah. If you're pausing the recording also, um I can show you what the class looks like so maybe it's more interactive that way.\n\n[30:20] Speaker2: Yep, sure. Uh let me pause it first. Stop.\n\n\n## Summary\n\nThe meeting began with a quick introduction from the speaker, who described their work in AI at OpenAI, focusing on reasoning agents. The core of the presentation revolved around the concept of \"leverage\" in the context of AI's impact on wealth creation and scientific progress.  The speaker illustrated three types of leverage: human labor, capital, and code/media, arguing that AI acts as a novel, powerful form of leverage, particularly in accelerating scientific advancement.  \n\nThe speaker then discussed the limitations of traditional leverage mechanisms, like human labor, due to increasing overhead in large collaborations.  In contrast, AI significantly reduces this overhead, potentially leading to smaller, highly productive teams and a shift in the definition of valuable skills.  They used the example of human vision, a complex and abundant human capability, versus more scarce skills now needed due to technological advancements.\n\nThe presentation concluded by emphasizing the potentially underestimated transformative impact of AI, especially in its ability to facilitate scientific progress by acting as a powerful new leverage mechanism, assisting with both learning and generating new ideas. They suggested that AI will be crucial in navigating the challenges of increasing complexity in scientific research.  The conversation briefly touched upon the concept of the technological singularity, concluding with a suggestion for a more interactive format.\n\n\n## Speaker Analysis\n\n**Speaker 1:**  This speaker asked the introductory question and had a concluding thank you. Their role is primarily that of a facilitator.  Communication style is brief and concise.\n\n**Speaker 2:** This speaker presented the main content.  Their role is the presenter. Their speaking style is detailed, thoughtful, and uses many technical terms. They clearly have deep knowledge of the subject.\n\n\n## Emotional Dynamics\n\nThe meeting maintained a professional and thoughtful atmosphere throughout. Speaker 2 presented their ideas with quiet intensity and passion, conveying a sense of excitement and perhaps some urgency about the transformative nature of AI.  The brief exchange at the end suggests a collaborative and open atmosphere where different viewpoints are welcome. There was a slight technical glitch, but it didn't significantly disrupt the flow or the overall positive tone.\n",
        "transcript": "[00:00] Speaker1: So, do you want to maybe give a really quick intro of yourself before we get started?\n\n[00:05] Speaker2: Yeah, sure. Um, so uh I'm [speaker2's name] and good to be here today. So, um I have been working on this AI stuff for a few years uh and um I have at OpenAI, I've been mainly um focusing on 01 preview, 01 and most recently Deep Research and now I'm more on the this agent side of things and so um yeah, very excited about reasoning and uh agents and just those things um so Okay, great. Um Right, let me get started. So uh I will talk about some AI stuff today, obviously, but before that, let's actually um start looking at um let's see. Right. Um this ChatGPT generated uh image of a flower, a budding flower. If you stare at this um for like a minute or 10 minutes, you don't really see any change. Does that mean there is no change underlying this process? There is. And if you wait long enough, then you'll see some big changes to a full-blown uh rose. And so what I'm trying to get at with this uh toy image is that we're really not good at um perceiving the changes that occur in, you know, like minute or like even uh days or years, but we're pretty good at um minute and hour scale changes. So I think there's probably a evolutionary explanation for this uh where if you can uh perceive the changes in um in the environment uh in the changes in minutes, probably very helpful for survival. And if you for like changes in over a year, not so much. Um so I think that probably uh is some some built-in um uh deficiency uh that we probably need to correct. So um why am I talking about this? I think um actually AI is a probably the the fastest moving technology of all time. Even then it doesn't move in like minutes or hours. It still moves over a few years timeframe or even decades. So um I think given this um deficiency I just talked about, we might be underestimating the change, especially the magnitude of the change uh this AI is bringing about. And so um I think at this point I don't have to convince that AI is important. Even a few years ago I start um my talk like that, but now I think that's given. But I do want to emphasize that maybe what everyone's thinking about how big of this change is uh is very different uh and if anything think we might be underestimating it and especially for um this AI which I'm gonna argue as a leverage mechanisms for uh individuals and humanity as a whole, that aspect uh might be somewhat underestimated. I'll get into the details of what what I mean by that, but let's build uh intuition slowly at a time, starting with this uh key word leverage. So it's a very important concept and used in a somewhat um casual way, informally and sometimes overloaded in and um depends on this context. Uh especially in the Silicon Valley area, this term is used a lot. I think this is such an important word that uh it's worth spending some time and building intuition around this. So uh for me, the first encounter of this concept was probably this classical mechanics where uh we have this uh lever. So in this case let's think about this um try to uh put it some pressure force down on the left-hand side on the screen and then as an output of that the the the we're kind of um lifting up that 1 kg uh mass on the right. So the lever, if we enlarge this uh lever um and then we can actually um you know, lift up heavier objects. So what this means is that the input downward force is the same, but by increasing this leverage, the output was increased by 3x. And so um this actually is a very general concept and I would like to um call out uh maybe this is my working definition of leverage. It's a mechanism through which a small change or no change in input results in larger change or very large change in output. Um and this is a very general thing and it's not just about the classical mechanics context that we just saw. I think it can be applied to many other places. Um and so this actually is a um you know, very important concept and I you know, we many people want to increase the output. I want to um contribute more, I want to generate more. Um then the first thing, the most natural thing that comes to uh our mind uh is probably how do I work harder? How can I increase my input? Um I want to like sleep less and um um you know, things like that. But I think that's there's a certain limit to it. Instead, the more important question is how do I increase the output without actually increasing the input? Or how can I disconnect the relationship between the input and the output or linear relationship between them? And that is getting at uh to the core of this leverage mechanism. And so what you're looking for there is um what leverage mechanism do I have and can I have? And that's uh if you want to increase the output, that's the question that we have to think about. And as a general concept, many many um different ways of thinking about this leverage. My personal favorite is by uh Naval Ravikant and from this um book, actually I have it um you know, in the in here. I strongly recommend it. So this is um uh not by his book, but it's just a collection of uh many of his thoughts like uh tweets and so on. According to Naval, there are three uh types of uh leverage and human labor, capital and code and media. So let's think about uh these things um uh individually. So first type is the human labor and this is the oldest type of uh leverage and and as such probably the most familiar one. And so as an example, um let's think about a scenario where I want to build a pyramid. Without the leverage, I will be building alone and that's probably quite difficult. And with leverage, I can hire uh thousands of human workers. And so my input uh is probably the same or uh even less, I don't have to work as much, but the output is much higher because there are thousands of people working on this. So this is um kind of a uh the leverage type with the permission because I need to ask the permissions of these uh people. And uh we still have this uh human labor as one of the main leverage mechanisms in the society. Second type is the capital. So uh let's think about this um a scenario where I want to invest in a real estate uh that's worth a million dollar. I only have 200k. So I do borrow 800k from a bank. And let's say I get lucky and this thing gets um doubled in valuation to 2 million. Um I it just doubled, but my uh return is 400% or 500% but it just went up by like a lot more because I just borrowed more from it. Um and so this is kind of the uh second type and I think it's more of a common common thing for uh 20th century and and so on. So third type is more recent uh thing especially more common in the the area, which is the code. And so more of a software type. And so if I write a code for an app, I build it and then there's one user who gets the value N. Um let's suppose that number is positive. And while I'm sleeping, one more user downloads it and installs it and gets another value N. So I'll put just double without me having to do any additional work. So this is possible because it's a software which is uh you know, copied and pasted, which is a very interesting nature of this and a lot of the recent value has been created uh leveraging that. So in media is similar in that um let's say I uh give a lecture to 200 people. Um those people got some value, again assuming that's uh positive. I posted on YouTube. Any additional view of the same lecture, I don't have to do any work, but somehow the value goes up and the limit is actually um uh pretty much endless. So that's the the new type of leverage too. And historically large wealth creation um utilizes these forms of leverage. And so um like the 20th centuries uh wealth a lot of them financial industries um leveraged a lot of this capital leverage. And then um recently, especially in this um area tech companies have leveraged the fact that if you write a code, the output can be multiplied pretty much indefinitely. And then um so those are the wealth creation mechanisms and if you look at the history of wealth um big wealth generated and you can probably identify such a leverage. So but then the upside of the leverage mechanism is also um competed away. And so what I mean by that is if something is good, then many people realize it and that's gonna be um uh competition. So if you start a company that is only leveraging this um the fact that it's a software, doesn't leverage other technologies, then it's probably much harder to uh succeed now compared to say 20 years ago. Or maybe um I'm less familiar with this, but YouTuber, you want to become a YouTuber now, probably more difficult than uh 10 years uh ago just based on the competition. So what I'm trying to get at is um when this leverage mechanism is uh just became possible because of some technology, much larger values and returns are possible then uh and then it's gonna be competed away. So I think it's a very important to think about what are the new leverage mechanisms that are becoming available. And so um obviously I'm gonna argue that AI is the um relatively new one that is coming into the picture and it's slowly expanding its the scope and reach. Um so to from an individual level to um you know, groups of people and to the point where it can uh benefit uh entire humanity. So let's maybe start looking at this uh at an individual level. Um I personally use AI or ChatGPT for me is um it in a education context. So I um that's probably the biggest one for me. And I think I spend a lot of time, especially uh weekends uh just learning about new concepts and um asking Now I think talk about this AI uh even hours and just learning about new things. And so here just again, if you think about leverage uh when I think about AI as a leverage, uh the learning what what is an input and output? The input is my time and effort to understand some concept that I don't understand. And the output is the conceptual understanding happening uh in my brain and maybe also some knowledge, but that's uh that's of an important thing. So with the AI this given input results in um you know, larger output. So let's say if I'm trying to um learn some specific things about a distributed system, um then before this kind of a generative AI, I would have to you know, Google this and then probably a Wikipedia page, which is typically not beginner friendly. So I'll be uh reading it, then I don't understand and probably don't feel good and then I'll try to find a uh introductory course maybe and textbook, but then I want only one concept out of this, but I kind of have to build around the context, at least terminologies and that's very time consuming. Now, because the AI can uh contextualize everything I know and generate dynamically just the right amount of materials at the right difficulty, I can uh much learn much easier. So I think that's the the the big uh lessons from the learning. So um what I'm saying is the barrier to learn a new area is like collapsing essentially. Um this is good and you probably heard about this a lot, but is this good just everywhere? I I think there's some uh we have to be careful and have a comprehensive look. And then um when everything is um easier to learn, people are learning everything, then there's an opportunity cost of not learning is getting higher. Um so as an extreme example, if you don't use AI, you just don't think about it at all and you just do your thing, you're not lazy, just doing your own thing and everyone else is just learning new things and uh getting better and um so on, then you're kind of behind uh in the society. That's the opportunity cost of just you don't contribute to it, but just because uh it's um the relatively um decided what the valuable skill is, that's uh what's happening. So um yeah, I think the in in this the society the valuable skill is um determined based on um the supply and demand and what is scarce um as opposed to an objective value it provides. So um I think one extreme example is a human vision. Um and it's a from objective perspective, this is a extremely complicated and advanced um feature. And if you study the computer vision, probably know that oh human vision is incredible. Like you sometimes recognize uh your friends or in a setting where it probably is very difficult um and you got you sometimes get surprised. But this incredible um capability is so abundant um that it's uh having that doesn't help you excelling in the modern society. Um and so I think um similarly just uh like scarcity is a very important um necessary condition for any uh highly valuable skill. So um and I often think about what are uh some great skills or opportunities to to have. And often a good good uh rule of thumb is uh whatever evolution did not teach equip us, then um that's kind of a good starting point uh because if it did, then everyone has it built into DNA and that's probably not that uh scarce. So um that's kind of the yeah, uh my this some implications of learning getting easier, which is not probably not that uh obvious. And so this acquisition of the new knowledge gets cheap, the scarcest factor is the the this motivation to to explore and curiosity is kind of the characteristics that probably will be more important. So, well I mean it has been always important, but I think it's getting more and more um because the learning um cost is going down but not zero. So you still have to overcome this um barrier. When learning a new concept is not something um that I would say everyone finds pleasing because you feel challenged and this cognitive um challenge is not um comfortable. And so to overcome that, uh curiosity can be like I I know there's a pain, but I need to get this because I'm so uh curious about it. That's a really uh strong force. If you're not curious, I think there's a way to kind of um have a correction mechanism, um which is okay, I I I'm gonna go through this uh short-term pain, but there will be a long-term um rewards, some fulfilling um things happening. So if you build enough of this rewards on psychological thing, we can uh get over it. But but anyway, uh broad more broadly technology changes what is scarce um just makes um and just being aware of the such changes um even if you're not directly contributing to it, uh is um I think uh very important. So that one uh learning affecting learning uh is one way AI is acting as a leverage. The other maybe more um uh intuitive one is this uh AI agent. Uh this is probably the most um interesting research area in 2025 and many more. Um so uh here AI agent is um kind of combining the uh the two types of leverage mechanisms that we uh saw before. First one is the human labor because AI agent is doing the work for you. So that's kind of the human labor part, uh as if you hired them. And then the second part is um at least the the the current um AI agents are um you know, software uh only. And so you can kind of copy and paste. If you want um 10 outputs, 10 agents working together, you just do it. If you want 12, then just copy uh two more. And you don't have to ask for the permission, just permissionless uh form of uh composite leverage mechanism that I think is uh quite profound if you think about it. Um so I think that's gonna be um um main um source of uh wealth generation uh going forward. And this thing is very new. I think it's just got started. Um I if you have used a Deep Research, that's um to me the most uh well functioning uh AI agent as of now. Uh there will be more probably, but uh that's at least uh the kind of the first uh working agent for me. Uh and so that increases my uh output by a lot and maybe probably many others too. So individuals are quite uh supercharged. And this means um you know, small teams consist of uh individuals um generating really big values. That's becoming more and more common. So in the you might heard about uh startups with like 10 people, 20 people generating like hundreds of millions of dollars of revenue. Uh that probably is un uh just imaginable like 10 years ago. But now still uncommon, but uh we're seeing this and I think behind the scene uh it's more of a AI acting as a leverage and individuals are just generating a lot more um outputs. And so previously, if you want to increase the output, then you again, you want to think about the leverage mechanism and after raising funds and whatever for capital leverage is uh out of question, then you have to really think about this human labor leverage and hire more people. But then uh human collaboration, especially at larger scale has quite a bit of overhead. Um there's communication, um you know, just uh it's a very difficult uh problem um and maybe some people don't get along with uh other people. And so just adding one person to say 100 person uh group doesn't mean the output goes up by 1%. It can even be um negative or uh can be anything. So um now with supercharged individuals, this um overhead uh is becoming less favorable and maybe we'll see more and more of uh smaller teams generating um uh quite a bit of uh value and more of a companies might be of this size. And obviously there will be big companies, but uh this might be a more common thing. And I think so far this has been like a individual level and uh some implications of the group as a result. Um I think there slowly uh again this is like a the the the flower analogy from the beginning, this is a change that is very big, but uh it's so slow that I think it's kind of an under uh estimated by many people and it's acting at the humanity's level. So let's think about uh this uh So if we think about the the just all of humans here, um what is the the task or goals um we might have? Uh I think this there's no right answer, but to me one of the most important things is to continue to generate um value and to thrive. And so what is the most um sustainable engines of growth and um value creation? Uh there are many probably, but for me the most sustainable engine is um scientific advances. Um discovering new knowledge and suddenly uh the like you know, what you think about as a thought about as a non-resource just becomes resource because now you have a new knowledge to leverage that um oil for example is just sticky uh liquid. Now you know how to do this um burn this and thermodynamic uh understanding you can uh that's a such a valuable resource. Um many instances like that. So um here um if we think about from historical perspective, since the like 17th century or roughly that time, scientific revolution uh the the wealth creation just um uh like really took off and like a hockey stick uh shape of uh economic metric um since then. Um and back then it was there were probably a lot of low hanging fruits in terms of the scientific progress uh because if you're the first one to do science, then probably there's a lot of easy things to do. Uh I'm not saying everything was easy because there's other challenges given the context, but still from an objective complexity perspective, this is probably much easier than what is happening now. So advancing science in modern society is a lot more complicated. So maybe we can think about uh Newtonian versus quantum mechanics or if you want to make a um you know, advanced uh chip making, advanced computer chips, uh that is probably beyond any single uh human's uh capability way beyond that. So it's getting a lot more complicated and involves um sometimes involves larger collaborations among people and more capital and so on. And also in addition to this uh increasing complexity of the technologies, studying technologies, human intelligence is not growing. Uh it's I don't even know it's growing, but it's kind of a stagnant compared to the rate at which the scientific complexity increases. So um these factors uh put together, I think are kind of the uh bottlenecks in the further advancing this um core mission of uh keep advancing scientific progress. So um we have done great job whenever just um bottleneck happens, we find a way to get uh out of it and we build the tools to unblock ourselves from uh achieving the mission. This time I think we should do the same thing with the AI being this tool that will um be the most useful thing and maybe even better a superhuman in the research capabilities so that we can continue this uh scientific advances. And I I think there are many purposes of AI, but to me this is the most um important, single most important purpose of it is to augment uh in continuing this uh grand mission of scientific advances. So uh now again just from the perspective of the leverage, uh let's think about the input and the output. The input is the collective human efforts um scientists here and there, uh just working together or like implicitly together. Uh and then the output is the scientific um you know, this progress uh of all. And so um what how can AI act as a leverage here? Um I think I'm gonna mention like two different things. First one is um you know, when um actually uh let's think about this. Uh we highly uh encourage being a specialist, especially in the scientific community. So uh there are small number of people who have a specialized knowledge and they're kind of segregated in different even uh you know, locations and communities and and so on. So it's hard to um collaborate. Uh you might not even know what is available option for collaboration across different uh expertise areas. And so to me this uh if you think about this human knowledge, a mental mental picture I have is a very sharp um in you know, high high-dimensional space and that's like here and there and just um there's so much uh space between them. And I think AI is acting as a um kind of an envelope around this uh spiky uh space and connecting all these um you know, the specialist knowledge. And if you're familiar with the um optimization, this is like the convex hole, this envelope around this um sharp uh you know, corners here and there. And I think this is the um the the one of the roles of uh AI. So this when I was uh working on the Deep Research, this um wasn't really obvious, but as I worked more and more and get more value out of it, this is kind of the mental picture I started building. And so um here I'm trying to get at this um human experts um very specialized, but um their you know, cooperation has uh communication, physical separations all all these um uh overhead. And this um AI is kind of making that much much um more uh you know, efficient. And so um what I'm what I think is uh might be happening already is uh because of those um separations um and uh unable to cooperate in an efficient manner, we might have a huge overhang of uh existing knowledge synthesis. So even with um you know, just combining the existing knowledge, we might be able to get a lot of value and maybe we can call that new knowledge. And so those are the uh I think uh completely uncharted territory just because of how experts have uh grown and the communication bottlenecks of um uh many many people. And so these are I think the low hanging fruits uh of AI you know, acting as a leverage to advancing the science mission. And but I don't think that's that's enough. Uh we should probably go beyond. And maybe just uh going forward uh we can expect advanced reasoning, maybe even better than uh human scientists and then ability to generate new ideas and knowledge. Uh I think this is still rare and maybe I'm hearing some you know, vague um uh anecdotes that these are possible, um like 03 helping some scientists generate new ideas, brainstorming partner, but I think it can go a lot more than that. And so I would expect that this kind of uh abilities emerge in the future generations of the model if not already in there. And once that happens, this will be um you know, just nonstop being um research engine that have works all the time and then they can work together uh across humans and agents and so on. This will be the main um leverage factor going forward, how AI can help help this uh mission of the scientific progress. So um that's all I have today and I've talked about many different concepts, but uh I think AI is just important thing everyone knows that, but um I would invite you to think about is this um how big of a change am I um thinking about and uh is there a possibility that I might be underestimating uh that magnitude especially um now that you think about from a new form of leverage. Um I would invite you to think about this. Um yeah, that's it. Thanks.\n\n[29:50] Speaker1: Thanks so much. Um Uh so your final point actually uh reminded me of something we talked about a couple weeks ago in the class called uh do you guys remember what it was called? Uh we talked about the singularity and uh uh how AI intelligence uh will reach a level where uh they surpass human intel Well, you know, obviously we're already at that point. Um do you think it relates to uh concepts such as that?\n\n[30:00] Speaker2: *Thoughtful pause, then a brief technical interruption regarding screen sharing.* Um not not because I'm going to say something. Okay, yeah. If you're pausing the recording also, um I can show you what the class looks like so maybe it's more interactive that way.\n\n[30:20] Speaker2: Yep, sure. Uh let me pause it first. Stop.",
        "summary": "The meeting began with a quick introduction from the speaker, who described their work in AI at OpenAI, focusing on reasoning agents. The core of the presentation revolved around the concept of \"leverage\" in the context of AI's impact on wealth creation and scientific progress.  The speaker illustrated three types of leverage: human labor, capital, and code/media, arguing that AI acts as a novel, powerful form of leverage, particularly in accelerating scientific advancement.  \n\nThe speaker then discussed the limitations of traditional leverage mechanisms, like human labor, due to increasing overhead in large collaborations.  In contrast, AI significantly reduces this overhead, potentially leading to smaller, highly productive teams and a shift in the definition of valuable skills.  They used the example of human vision, a complex and abundant human capability, versus more scarce skills now needed due to technological advancements.\n\nThe presentation concluded by emphasizing the potentially underestimated transformative impact of AI, especially in its ability to facilitate scientific progress by acting as a powerful new leverage mechanism, assisting with both learning and generating new ideas. They suggested that AI will be crucial in navigating the challenges of increasing complexity in scientific research.  The conversation briefly touched upon the concept of the technological singularity, concluding with a suggestion for a more interactive format.",
        "speakerAnalysis": "**Speaker 1:**  This speaker asked the introductory question and had a concluding thank you. Their role is primarily that of a facilitator.  Communication style is brief and concise.\n\n**Speaker 2:** This speaker presented the main content.  Their role is the presenter. Their speaking style is detailed, thoughtful, and uses many technical terms. They clearly have deep knowledge of the subject.",
        "emotionalDynamics": "The meeting maintained a professional and thoughtful atmosphere throughout. Speaker 2 presented their ideas with quiet intensity and passion, conveying a sense of excitement and perhaps some urgency about the transformative nature of AI.  The brief exchange at the end suggests a collaborative and open atmosphere where different viewpoints are welcome. There was a slight technical glitch, but it didn't significantly disrupt the flow or the overall positive tone.",
        "cost": {
          "inputTokens": 316,
          "outputTokens": 6941,
          "inputCost": 0.00039499999999999995,
          "outputCost": 0.06941,
          "totalCost": 0.069805
        },
        "processingTime": 79334,
        "tokenUsage": {
          "promptTokenCount": 46089,
          "candidatesTokenCount": 6106,
          "totalTokenCount": 52195,
          "promptTokensDetails": [
            {
              "modality": "TEXT",
              "tokenCount": 264
            },
            {
              "modality": "AUDIO",
              "tokenCount": 45825
            }
          ],
          "candidatesTokensDetails": [
            {
              "modality": "TEXT",
              "tokenCount": 6106
            }
          ]
        },
        "timestamp": 1756205360579,
        "audioFilePath": "audio-temp/twitter-video-test.wav"
      },
      "totalCost": 0.069805,
      "processingTime": 79334,
      "status": "success"
    }
  },
  "recommendation": "pipeline b (gemini end-to-end) - only working option"
}